{"type":"object","id":0,"value":{"url":{"type":"string","value":"https://github.com/spotify/annoy"},"repo_id":{"type":"string","value":"spotify/annoy"},"readme":{"type":"string","value":"Annoy\n-----\n\n\n\n.. figure:: https://raw.github.com/spotify/annoy/master/ann.png\n   :alt: Annoy example\n   :align: center\n\n.. image:: https://github.com/spotify/annoy/actions/workflows/ci.yml/badge.svg\n    :target: https://github.com/spotify/annoy/actions\n\nAnnoy (`Approximate Nearest Neighbors <http://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor>`__ Oh Yeah) is a C++ library with Python bindings to search for points in space that are close to a given query point. It also creates large read-only file-based data structures that are `mmapped <https://en.wikipedia.org/wiki/Mmap>`__ into memory so that many processes may share the same data.\n\nInstall\n-------\n\nTo install, simply do ``pip install --user annoy`` to pull down the latest version from `PyPI <https://pypi.python.org/pypi/annoy>`_.\n\nFor the C++ version, just clone the repo and ``#include \"annoylib.h\"``.\n\nBackground\n----------\n\nThere are some other libraries to do nearest neighbor search. Annoy is almost as fast as the fastest libraries, (see below), but there is actually another feature that really sets Annoy apart: it has the ability to **use static files as indexes**. In particular, this means you can **share index across processes**. Annoy also decouples creating indexes from loading them, so you can pass around indexes as files and map them into memory quickly. Another nice thing of Annoy is that it tries to minimize memory footprint so the indexes are quite small.\n\nWhy is this useful? If you want to find nearest neighbors and you have many CPU's, you only need to build the index once. You can also pass around and distribute static files to use in production environment, in Hadoop jobs, etc. Any process will be able to load (mmap) the index into memory and will be able to do lookups immediately.\n\nWe use it at `Spotify <http://www.spotify.com/>`__ for music recommendations. After running matrix factorization algorithms, every user/item can be represented as a vector in f-dimensional space. This library helps us search for similar users/items. We have many millions of tracks in a high-dimensional space, so memory usage is a prime concern.\n\nAnnoy was built by `Erik Bernhardsson <http://www.erikbern.com>`__ in a couple of afternoons during `Hack Week <http://labs.spotify.com/2013/02/15/organizing-a-hack-week/>`__.\n\nSummary of features\n-------------------\n\n* `Euclidean distance <https://en.wikipedia.org/wiki/Euclidean_distance>`__, `Manhattan distance <https://en.wikipedia.org/wiki/Taxicab_geometry>`__, `cosine distance <https://en.wikipedia.org/wiki/Cosine_similarity>`__, `Hamming distance <https://en.wikipedia.org/wiki/Hamming_distance>`__, or `Dot (Inner) Product distance <https://en.wikipedia.org/wiki/Dot_product>`__\n* Cosine distance is equivalent to Euclidean distance of normalized vectors = sqrt(2-2*cos(u, v))\n* Works better if you don't have too many dimensions (like <100) but seems to perform surprisingly well even up to 1,000 dimensions\n* Small memory usage\n* Lets you share memory between multiple processes\n* Index creation is separate from lookup (in particular you can not add more items once the tree has been created)\n* Native Python support, tested with 2.7, 3.6, and 3.7.\n* Build index on disk to enable indexing big datasets that won't fit into memory (contributed by `Rene Hollander <https://github.com/ReneHollander>`__)\n\nPython code example\n-------------------\n\n.. code-block:: python\n\n  from annoy import AnnoyIndex\n  import random\n\n  f = 40  # Length of item vector that will be indexed\n\n  t = AnnoyIndex(f, 'angular')\n  for i in range(1000):\n      v = [random.gauss(0, 1) for z in range(f)]\n      t.add_item(i, v)\n\n  t.build(10) # 10 trees\n  t.save('test.ann')\n\n  # ...\n\n  u = AnnoyIndex(f, 'angular')\n  u.load('test.ann') # super fast, will just mmap the file\n  print(u.get_nns_by_item(0, 1000)) # will find the 1000 nearest neighbors\n\nRight now it only accepts integers as identifiers for items. Note that it will allocate memory for max(id)+1 items because it assumes your items are numbered 0 â€¦ n-1. If you need other id's, you will have to keep track of a map yourself.\n\nFull Python API\n---------------\n\n* ``AnnoyIndex(f, metric)`` returns a new index that's read-write and stores vector of ``f`` dimensions. Metric can be ``\"angular\"``, ``\"euclidean\"``, ``\"manhattan\"``, ``\"hamming\"``, or ``\"dot\"``.\n* ``a.add_item(i, v)`` adds item ``i`` (any nonnegative integer) with vector ``v``. Note that it will allocate memory for ``max(i)+1`` items.\n* ``a.build(n_trees, n_jobs=-1)`` builds a forest of ``n_trees`` trees. More trees gives higher precision when querying. After calling ``build``, no more items can be added. ``n_jobs`` specifies the number of threads used to build the trees. ``n_jobs=-1`` uses all available CPU cores.\n* ``a.save(fn, prefault=False)`` saves the index to disk and loads it (see next function). After saving, no more items can be added.\n* ``a.load(fn, prefault=False)`` loads (mmaps) an index from disk. If `pre... [truncated]"},"repo_name":{"type":"string","value":"annoy"},"author":{"type":"string","value":"spotify"},"topics":{"type":"array","id":1,"value":[{"type":"string","value":"approximate-nearest-neighbor-search"},{"type":"string","value":"c-plus-plus"},{"type":"string","value":"golang"},{"type":"string","value":"locality-sensitive-hashing"},{"type":"string","value":"lua"},{"type":"string","value":"nearest-neighbor-search"},{"type":"string","value":"python"}]},"language":{"type":"string","value":"C++"},"stargazers_count":{"type":"number","value":"13670"},"forks_count":{"type":"number","value":"1187"}}}